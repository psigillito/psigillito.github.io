<!DOCTYPE html>
<html>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<head>
		<link rel="stylesheet" href="styling.css">
	</head>
	<div class="header">
		<h1>Philip Sigillito</h1>
		<h2>psigillito@gmail.com | https://github.com/psigillito </h2>
		<h2><a>Resume</a> | <a>LinkedIn</a></h2>
		<div> 
			Thank you for visiting my portfolio page! Down below you will see some of my past projects. Feel free to email me with any questions. 
		</div>
	</div>
	<br>
	
<div class="fluidSection">
	<h2 style="text-align:center;">Interactive Fluid Simulation</h2>
	<div class="options">
		Interactive Fluid simulation. Hold down left mouse button and drag to interact. Simulates an incompressible fluid using Navier Stokes equations. 
		Velocity Lines option diplays decomposed velocity vectors for each cell of the grid. 
		<br>
		<input type="radio" name="display" value="lines" id="lines">Velocity Lines</input>
		<input type="radio" name="display" value="pixels" id="pixels" checked="checked">Pixels</input>
	</div>
	<br>
	<div style="justify-content: center;">
		<canvas  id="myCanvas" style="border:2px solid;"></canvas>	
	</div>
</div>

<body>
	<div class="header">
		<h1>Projects</h1>
	</div>
	<div id="paper-div" class="paper">
		<div class="imageDesc">
			<img id="IR Code" alt="IR Code" width="250" height="238"src="LLVMBlack.png">
		</div>
		<div class="textDesc">
			I contributed to a research project using Clang and the LLVM compiler. We altered generated code blocks from the Clang front-end to imprint a 
			unique watermark on compiled software. I wrote the optimization passes that alter the IR code blocks to apply the watermark. Clang and LLVM are both open-source with active communities. After completing this project, 
			I made some modest contributions to Clang's formatter subsystem.  
			<br>
			<a href="https://papers.academic-conferences.org/index.php/iccws/article/view/39">LLVM Paper</a>
		</div>
	</div>
	
	<div id="paper-div" class="paper">
		<div class="imageDesc">
			<img id="IR Code" alt="IR Code" width="250" height="250" src="byzantineKing.jpg">
		</div>
		<div class="textDesc">
		<span style="vertical-align: middle;" class="textDesc">
			Simulates a generic block-chain network where each node is its own flask server. The nodes 
			communicate with each other through HTTP to send 'mined' blocks, propogate results, and verify each other. The simulation focuses on how byzantine failures 
			impact network performance. This is when the node starts sending incorrect information (sometimes maliciously) but it is not apparent that the node is acting incorrectly. 
			This is based on the byzantine general problem which is a commonly discussed issue in distributed voting systems. 
			<br>
			<a href="ByzantineNodesinBlockchain.pdf">Paper</a>
		</div>
	</div>
	<br>

	<div id="paper-div" class="paper">
		<div class="imageDesc">
			<img id="IR Code" alt="IR Code" width="250" height="250" src="openCL.png">
		</div>
		<div class="textDesc">
		<span style="vertical-align: middle;" class="textDesc">
			We measured how offloading parallelizable tasks to the GPU can improve performance. Using the GPU does require some overhead as there is a cost to sending the 
			data and instructions to the GPU. There is an additional cost to reading the results back form the GPU. APIs for running code on the GPU such as OpenCL and Cuda also 
			give the developer the freedim to specify how the GPU runs:  number of work groups, number of cores in each workgroup, etc. This project looked at what the 'tipping point'
			is for when the overhead cost outweighs the benefit for offloading computation to the GPU. We also looked at parallelization on the CPU using OpenMP although this is not included in the report. 
			<br>
			<a href="OpenCLBenchmarking.pdf">OpenCL Benchmarking</a>
		</span>
		</div>
	</div>
	<br>

	<div id="paper-div" class="paper">
		<div class="imageDesc">
			<img id="IR Code" alt="IR Code" width="300" height="300" src="NeRF.JPG">
		</div>
		<div class="textDesc"> 
		<span style="vertical-align: middle;" class="textDesc">
			Volumetric rendering is a really interesting field computer graphics. NeRFs combine its techniques with deep learning. Neural radiance fields, NeRFs, became really popular when debuted at SIGGRAPH 2020. 
			These networks take a set of static images of a scene and then train a convolutional network to generate novel views of that scene not included in the image set. My paper is really an excuse to build a NeRF 
			from scratch based on the 2020 paper. The future of NeRFs is really exciting as new research has been done to reduce the number of images need to generate a 3D scene, allow images with lots of noise, and 
			even develop single-shot techniques that use pretrained networks to generate pretty good models based on a single image. 
			
			I think NeRFs will play a part in future 3D asset generation. For example, say you want a 3D model of the eiffel tower, you could scrape the internet for images of it and train a NeRF to generate the scene. You could then use 
			a technique like marching cubes to generate a 3D asset. Pretty soone people will be able to generate 3D scenes of imporant moments like a wedding just off of their phone. 

			<br>
			<a href="NerfsSurvey.docx.pdf">Exploring Neural Radiance Fields</a>
		</span>
		</div>
	</div>
	<br>
	<div id="paper-div" class="paper">
		<img id="IR Code" alt="IR Code" width="300" height="300"
			src="StarPattern.JPG">
		<span style="vertical-align: middle;" class="textDesc">
			There are a lot of interesting algorithms for identifying a star based on a limited view of its surrounding stars. These algorithms have a practical application 
			for navigation especially for satellites determining their attitude. I implimented a novel algorithm from a 2017 paper that introduces a novel algorithm for decomposing 
			the stars surrounding the target star into a hash table of values. The algorithm assigns each star a value based on its distance from the target star and assigns it
			to a hash table based on its angle assumming that the target star is located at the center of a unit circle. The algorithm then uses Spearman correlation between our generated value 
			and the values of stars in a database to determine a match. 
			<br> 
			I love deep learning but this paper teaches a valuable lesson that more complicated AI is not always best. There are other examples online of training networks to identify stars. 
			At first this makes sense as deep-learning networks can be really good at classifying objects in images. On the other hand, this problem requires each star being its own classification. 
			Examples online, required training the network on each star individually which takes a long time and resources. In this case, a traditional pattern recognition algorithm was more performant. 
			<br>
			<a href="PhilipSigillito-ProjectReport.pdf">Star Identification using OpenCV and Novel Algorithm</a>
		</span>
	</div>
	<br>
	<div id="paper-div" class="paper">
		<img id="IR Code" alt="IR Code" width="300" height="300"
			src="HAR.jpg">
		<span style="vertical-align: middle;" class="textDesc">
			I compared several different neural network architectures and how they perform when classifying human activities (running, sitting, walking, etc.). 
			The datasets consist of sensor readouts from accelerometers, gyroscopes, and electromagmetometers. I looked at convolutional and recurrent networks. 
			Convolutional networks are really good at understanding spatial relationships in a single time-step. This is why they are so popular for image classification. 
			Recurrent networks are really good at understanding temporal relationships. For example, when training on a video clip the convolutional network would
			perform well at understanding the relationship of each object in a frame of the video whereas the recurrent network would learn how each frame of the video 
			relates to each other. 
			<br> 
			Serveral different recurrent network types were tests: RNN, LSTM, GRU, and BiLSTM. I found that using a convolutional network which feeds into 
			a self-regulating recurrent networks such as LSTM is the most performant and can achieve over 98 percent accuracy against validation data. I also did some hyperparameter tuning 
			which is an interesting field of research within deep learning. One interesting hyperparameter that is hard to predict the best value for is the kernel size of the 
			convolutional layers.     

			<br>
			<a href="PhilipSigillito-ProjectReport.pdf">Paper</a>
		</span>
	</div>
	<br>





<script>
	var canvas = document.getElementById("myCanvas");
	var c = canvas.getContext("2d");	
	canvas.width = 800;
	canvas.height = 800;
	var res = 100;
	var cellPixelWidth = canvas.width / res;
	canvas.focus();

	class Fluid {
		constructor(numX, numY) {
			this.rowCount = numY + 2;
			this.columnCount = numX + 2;
			this.numCells = numX * numY;
			this.u = new Array(this.rowCount);
			//X Velocities
			for(var i = 0; i < this.rowCount; i++)
			{
				this.u[i] = new Float32Array(this.columnCount).fill(0);
			}
			//Y Velocities
			this.v = new Array(this.rowCount);
			for(var i = 0; i < this.rowCount; i++)
			{
				this.v[i] = new Float32Array(this.columnCount).fill(0.0);
			}
			//Solid = 0 , Open = 1
			this.s = new Array(this.rowCount);
			for(var i = 0; i < this.rowCount; i++)
			{
				this.s[i] = new Float32Array(this.columnCount).fill(1.0);
			} 
			//Pressure Values 
			this.p = new Array(this.rowCount);
			for(var i = 0; i < this.rowCount; i++)
			{
				this.p[i] = new Float32Array(this.columnCount).fill(0.0);
			}
			
			//fill border around vector field with 1s 
			for(var i = 0; i < this.columnCount; i++)
			{
				this.s[i][this.columnCount-1] = 0.0;
				this.s[i][this.columnCount-2] = 0.0;
				
				this.s[0][i] = 0.0;
				this.s[1][i] = 0.0;

				this.s[i][0] = 0.0;
				this.s[i][1] = 0.0;

				this.s[this.columnCount - 2][i] = 0.0;
				this.s[this.columnCount - 1][i] = 0.0;
				
				this.s[numY][i] = 0.0;
				this.s[numY-1][i] = 0.0;
				this.s[numY-2][i] = 0.0;

				this.s[i][numX] = 0.0;
				this.s[i][numX-1] = 0.0;
				this.s[i][numX-2] = 0.0;
				
			}

			//new X velocities
			this.newU = new Array(this.rowCount);
			for(var i = 0; i < this.rowCount; i++)
			{
				this.newU[i] = new Float32Array(this.columnCount).fill(0);
			}
			//New Y Velocities
			this.newV = new Array(this.rowCount);
			for(var i = 0; i < this.rowCount; i++)
			{
				this.newV[i] = new Float32Array(this.columnCount).fill(0.0); //y velocities
			}
		}
	}

	var scene = 
	{
		mouseX: 0.0,
		mouseY: 0.0,
		mouseRadius: 0.15,
		dt : 1.0 / 3.0,
		//frameNr : 0,
		sceneNr: 0,
		fluid: null
	};

	function setupScene(sceneNr = 0) 
	{
		scene.sceneNr = sceneNr;
		scene.dt = 1.0 / 60.0; 
		scene.numIters = 40;
		scene.particleX = 400.0;
		scene.particleY = 400.0;
		f = scene.fluid = new Fluid(res, res);
	}

	function draw() 
	{
		c.clearRect(0, 0, canvas.width, canvas.height);
		c.rect(0,0,canvas.width, canvas.height);
		c.fillStyle = "#000000";		
		c.fill();

		if(document.getElementById('pixels').checked)
		{
			for(i = 0; i < res; ++i) //for each row
			{
				for(j = 0; j < res; ++j)
				{			
					c.beginPath();
					var r = 0; 
					var g = 0; 
					var b = 0;

					//color application based on color wheel from https://www.britannica.com/science/color/The-visible-spectrum
					if( scene.fluid.u[i][j] < 0 )
					{
						g += Math.abs(scene.fluid.u[i][j] * 10);
						b += Math.abs(scene.fluid.u[i][j] * 10);
						//apply cyan to color
					}
					else{
						r +=  Math.abs(scene.fluid.u[i][j] * 10);
						//apply red
					}

					if(scene.fluid.v[i][j] < 0 ) //up
					{
						//apply yellow
						r += Math.abs(scene.fluid.v[i][j] * 10);
						g += Math.abs(scene.fluid.v[i][j] * 10);

					}
					else //down
					{
						//apply purple
						r += Math.abs(scene.fluid.v[i][j] * 10);
						b += Math.abs(scene.fluid.v[i][j] * 10);
					}

					c.fillStyle = 'rgb(' + r + ',' + g + ',' + b + ')';  
					c.fillRect(j*cellPixelWidth, i*cellPixelWidth, cellPixelWidth, cellPixelWidth);
					c.stroke();
				}	
			}
		}


		else if(document.getElementById('lines').checked)
		{
			drawVelocityLines();
		}

		//draw particle 
		c.beginPath();
		c.arc(scene.particleX, scene.particleY, 10, 0, 2 *Math.PI);
		c.fillStyle = "#FF4400";
		c.fill();
		c.stroke();

	}

	function simulate() 
	{
		solveIncompressibility(scene.dt);
		advectVelocity(scene.dt);
		//move particle
		movementValueX = sampleSurroundingVelocities(scene.particleX, scene.particleY, 'u');
		movementValueY = sampleSurroundingVelocities(scene.particleX, scene.particleY, 'v');
		scene.particleX += movementValueX;
		scene.particleY += movementValueY;	
	}

	function update() {
		simulate();
		draw();
		requestAnimationFrame(update);
	}
	
	setupScene();
	update();
	
	//Mouse dragging logic
	var mouseDown = false;

	function startDrag(x,y){
		mouseDown=true;
		setObstacle(x,y,true);
	}

	function setObstacle(x,y,reset)
	{
		var velocityX = 0.0;
		var velocityY = 0.0;
		if(!reset){
			velocityX = (x - scene.mouseX)/scene.dt;
			velocityY = (y - scene.mouseY)/scene.dt;
		}
		scene.mouseX = x;
		scene.mouseY = y;
		var obstacleRadius = scene.mouseRadius;
		var fluid = scene.fluid;
		var rowCount = res;
		for(var i = 0; i < fluid.rowCount; ++i){
			for(var j = 0; j < fluid.columnCount; ++j)
			{
				uPixelCoord = convertToPixelCoordinate(j, i, cellPixelWidth,'u');
				vPixelCoord = convertToPixelCoordinate(j, i, cellPixelWidth,'v');

				var uDistance = Math.sqrt(
						Math.pow( (uPixelCoord[0] - x),2) 
						+ 
						Math.pow( (uPixelCoord[1] - y),2));

				var vDistance = Math.sqrt(
						Math.pow( (vPixelCoord[0] - x),2) 
						+ 
						Math.pow( (vPixelCoord[1] - y),2));

				//check u first
				if(	uDistance < 40  && scene.fluid.s[i][j] != 0.0 && scene.fluid.s[i][j-1] != 0.0 )  
				{
					scene.fluid.u[i][j] = 0.01 * velocityX;
				} 
				if(vDistance < 40 && scene.fluid.s[i][j] != 0.0 && scene.fluid.s[i-1][j] != 0.0)
				{
					scene.fluid.v[i][j] = 0.01 * velocityY;
				}
			}
		}
	}

	function drag(x, y) {
		if (mouseDown) {
			setObstacle(x,y, false);
		}
	}

	function endDrag() {
		mouseDown = false;
	}

	canvas.addEventListener('mousedown', event => {

		var rt = window.innerWidth - canvas.getBoundingClientRect().right; 
		var down = canvas.getBoundingClientRect().top; 
		
		startDrag(event.x - rt, event.y - down);
	});

	canvas.addEventListener('mouseup', event => {
		endDrag();
	});

	canvas.addEventListener('mousemove', event => {
		var down = canvas.getBoundingClientRect().top; 
		var rt = window.innerWidth - canvas.getBoundingClientRect().right; 
		drag(event.x - rt, event.y - down);
	});


	function drawVelocityLines()
	{
		for(var i = 0; i < scene.fluid.rowCount; ++i){
			for(var j = 0; j < scene.fluid.columnCount; ++j)
			{
				//flipped j, i because I am doing row major and canvas column major
				var pixelCoords = convertToPixelCoordinate(j,i, cellPixelWidth,'u');
				c.beginPath();
				c.moveTo(pixelCoords[0], pixelCoords[1]);
				var xOffset = scene.fluid.u[i][j];
				c.lineTo(pixelCoords[0] + (xOffset), pixelCoords[1]);
				c.strokeStyle = xOffset < 0 ? 'green' : 'red';
				c.fill();
				c.stroke();

				//flipped j, i because I am doing row major and canvas column major
				var vPixelCoords = convertToPixelCoordinate(j,i, cellPixelWidth,'v');
				c.beginPath();
				c.moveTo(vPixelCoords[0], vPixelCoords[1]);
				var yOffset = scene.fluid.v[i][j];
				c.lineTo(vPixelCoords[0], vPixelCoords[1] + (yOffset));
				c.strokeStyle = yOffset < 0 ? 'yellow' : 'blue';
				c.fill();
				c.stroke();
			}
		}
	}

	function convertToPixelCoordinate(xValue, yValue, cellWidth, coordType)
	{
		if(coordType == 'u')
		{
			pixelX = Math.floor(xValue * cellWidth); 
			pixelY = Math.floor( (yValue * cellWidth) + (cellWidth/2.0));
			return [pixelX, pixelY];
		}
		else
		{
			pixelX = Math.floor(xValue * cellWidth + (cellWidth/2.0)); 
			pixelY = Math.floor(yValue * cellWidth);
			return [pixelX, pixelY];
		}
	}

	function sampleSurroundingVelocities(pixelX, pixelY, velocityType)
	{
		if(velocityType == 'u')
		{
			var xIndex = Math.abs(Math.floor(pixelX/cellPixelWidth));
			var yIndex = Math.abs(Math.floor(pixelY/cellPixelWidth));
			
			var xNextIndex = xIndex+1 < scene.fluid.rowCount    ?  xIndex+1 : xIndex;
			var uVelocityLeft =  (scene.fluid.u[yIndex] === undefined || scene.fluid.u[yIndex][xNextIndex] === undefined) 
				? 0 : scene.fluid.u[yIndex][xNextIndex];
			var uVelocityRight = (scene.fluid.u[yIndex] === undefined || scene.fluid.u[yIndex][xIndex] === undefined)
				? 0 : scene.fluid.u[yIndex][xIndex];

			var insideCellPositionX = pixelX % cellPixelWidth;
			var leftWeight =  1.0 - ( (cellPixelWidth - insideCellPositionX) / cellPixelWidth);
			var rightWeight =  1.0 - leftWeight;

			var uVelocity = (leftWeight*uVelocityLeft+ rightWeight*uVelocityRight);// + uVelocityLeft)*0.5; //need to weight by distance 
			return uVelocity;
		}
		else
		{
			var xIndex = Math.abs(Math.floor(pixelX/cellPixelWidth));
			var yIndex = Math.abs(Math.floor(pixelY/cellPixelWidth));
			
			var yNextIndex = yIndex+1 < scene.fluid.rowCount  ?  yIndex+1 : yIndex;

			var vVelocityTop =  (scene.fluid.v[yIndex] === undefined || scene.fluid.v[yIndex][xIndex] === undefined) 
				? 0 : scene.fluid.v[yIndex][xIndex];
			var vVelocityBelow = (scene.fluid.v[yNextIndex]=== undefined || scene.fluid.v[yNextIndex][xIndex] === undefined) 
				? 0 : scene.fluid.v[yNextIndex][xIndex];
			var insideCellPositionY = pixelY % cellPixelWidth;

			var topWeight =  1.0 - ( (cellPixelWidth - insideCellPositionY) / cellPixelWidth);
			var bottomWeight =  1.0 - topWeight;
			var value = topWeight + bottomWeight;

			var vVelocity = (bottomWeight*vVelocityTop + topWeight*vVelocityBelow);// + uVelocityLeft)*0.5; //need to weight by distance 
			return vVelocity;
		}
	}


	function advectVelocity(dt){
	for(var i = 1; i < scene.fluid.rowCount-2; ++i)
	{
		for(var j = 1; j < scene.fluid.columnCount-2; ++j)
		{
			//update u
			//if this u and next u are not a solid object do advection 
			if(scene.fluid.s[i][j] != 0.0 && scene.fluid.s[i][j-1] != 0.0)
			{
				//get current location in pixels 
				var pixelX = j * cellPixelWidth;
				var pixelY = i * cellPixelWidth + (cellPixelWidth/2);
				var uVelocity = scene.fluid.u[i][j];
				
				var v1 = scene.fluid.v[i][j];
				var v2 = scene.fluid.v[i][j-1];
				var v3 = scene.fluid.v[i+1][j];
				var v4 = scene.fluid.v[i+1][j+1];
				var averageV = (v1+v2+v3+v4) * 0.25;

				var oldPixelX = pixelX - (uVelocity %10) ;
				var oldPixelY = pixelY - (averageV %10);

				var newVal = sampleSurroundingVelocities(oldPixelX,oldPixelY, 'u');
				scene.fluid.newU[i][j] = newVal;
			}
			if(scene.fluid.s[i][j] != 0.0 && scene.fluid.s[i-1][j] != 0.0)
			{
				//get current location in pixels 
				pixelX = j * cellPixelWidth + (cellPixelWidth/2);
				pixelY = i * cellPixelWidth;
				var vVelocity = scene.fluid.v[i][j];
				
				var u1 = scene.fluid.u[i][j];
				var u2 = scene.fluid.u[i][j+1];
				var u3 = scene.fluid.u[i-1][j];
				var u4 = scene.fluid.u[i-1][j+1];
				var averageU = (u1+u2+u3+u4) * 0.25;

				var oldPixelX = pixelX - (averageU % 100);
				var oldPixelY = pixelY - (vVelocity % 100);

				var newVal = sampleSurroundingVelocities(oldPixelX,oldPixelY, 'v');
				scene.fluid.newV[i][j] = newVal;
			}
		}
	}


	for(var i = 0; i < scene.fluid.rowCount; ++i)
	{
		for(var j = 0; j < scene.fluid.columnCount; ++j)
		{
			scene.fluid.u[i][j] = scene.fluid.newU[i][j];
			scene.fluid.v[i][j] = scene.fluid.newV[i][j];
		}
	}
}

	function solveIncompressibility(dt)
	{
		var iterations = 10;
		var cp = 10 / dt;
		for(var x = 0; x < iterations; x++)
		{
			for(var i = 1; i < scene.fluid.rowCount-1; ++i){

				for(var j = 1; j < scene.fluid.columnCount-1; ++j)
				{

					if(scene.fluid.s[i][j] == 0.0)
					{
						//bail on solid object
						continue;
					}
					 
					var sLeft = scene.fluid.s[i][j-1];
					var sRight = scene.fluid.s[i][j+1];
					var sUp = scene.fluid.s[i-1][j];
					var sBelow = scene.fluid.s[i+1][j];
					var sTotal = sLeft + sRight + sUp + sBelow;
					if(sTotal == 0.0)
					{
						continue;
					}

					var u1 = scene.fluid.u[i][j];
					var u2 = scene.fluid.u[i][j+1];

					var v1 = scene.fluid.v[i][j];
					var v2 = scene.fluid.v[i+1][j];

					var divergence = u2 - u1 + v2 - v1;
					
					var pressure = -divergence / sTotal;
					pressure *= 1.9;
					scene.fluid.p[i][j] += cp * pressure;

					scene.fluid.u[i][j] -= sLeft * pressure;
					scene.fluid.u[i][j+1] += sRight * pressure;
					scene.fluid.v[i][j] -= sUp * pressure;
					scene.fluid.v[i+1][j] += sBelow * pressure;
				}
			}
		}
	}
</script> 
</body>
</html>